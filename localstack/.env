# Scripts
export DATABASE_CSV='database.csv'
export HOST_DATA_DIRECTORY='data'

# Images
export SPARK_IMAGE='apache/spark-py'
export AIRFLOW_IMAGE='apache/airflow'
export LOCALSTACK_IMAGE='localstack/localstack'
export POSTGRES_IMAGE='postgres'
export REDIS_IMAGE='redis'

# Versions
export SPARK_IMAGE_VERSION='3.3.1'
export AIRFLOW_IMAGE_VERSION='2.5.0'
export LOCALSTACK_IMAGE_VERSION='1.3.1'
export POSTGRES_IMAGE_VERSION='15'
export REDIS_IMAGE_VERSION='7.0'

# Spark
export SPARK_ENTRYPOINT='bash -c'
export SPARK_USER='root'
export SPARK_BUILD_CONTEXT='docker/spark'
export SPARK_WORKER_DOCKERFILE='spark-worker.Dockerfile'
export SPARK_HOST_DATA_DIRECTORY='./data'
export SPARK_CONTAINER_DATA_DIRECTORY='/data'
export SPARK_MASTER_URL='spark://spark-master:7077'
export SPARK_WORKER_PORT='7077'
export SPARK_WORKER_CORES='2'
export SPARK_WORKER_MEMORY='2g'

# Airflow
export AIRFLOW_CONFIG_EXECUTOR='CeleryExecutor'
export AIRFLOW_CONFIG_SQL_ALCHEMY_CONNECTION='postgresql+psycopg2://airflow:airflow@postgres/airflow'
export AIRFLOW_CONFIG_RESULT_BACKEND='db+postgresql://airflow:airflow@postgres/airflow'
export AIRFLOW_CONFIG_BROKER_URL='redis://:@redis:6379/0'
export AIRFLOW_CONFIG_FERNET_KEY=''
export AIRFLOW_CONFIG_DAGS_PAUSED_AT_CREATION='true'
export AIRFLOW_CONFIG_LOAD_EXAMPLES='false'
export AIRFLOW_CONFIG_AUTH_BACKEND='airflow.api.auth.backend.basic_auth'
export AIRFLOW_CONFIG_DB_UPGRADE='true'
export AIRFLOW_CONFIG_WWW_USER_CREATE='true'
export AIRFLOW_CONFIG_WWW_USER_USERNAME='airflow'
export AIRFLOW_CONFIG_WWW_USER_PASSWORD='airflow'
export AIRFLOW_VARIABLE_PATH_TO_HELSINKI_CITY_BIKES_DATA='/data'
export AIRFLOW_VARIABLE_PATH_TO_HELSINKI_CITY_BIKES_FILE='/data/2018-07.csv'
export AIRFLOW_VARIABLE_PATH_TO_SPARK_TASKS_DIRECTORY='/opt/airflow/dags/spark'
export AIRFLOW_VARIABLE_AWS_S3_BUCKET_NAME='helsinki-city-bikes'
export AIRFLOW_VARIABLE_AWS_S3_DATA_OBJECT_KEY_PREFIX='data'
export AIRFLOW_VARIABLE_AWS_S3_METRICS_OBJECT_KEY_PREFIX='metrics'
export AIRFLOW_CONNECTION_AWS_DEFAULT='aws://mock_access_key:mock_secret_key@/?endpoint_url=http://localstack:4566&region_name=eu-north-1'
export AIRFLOW_CONNECTION_SPARK_DEFAULT='spark://spark%3A%2F%2Fspark-master:7077?deploy_mode=cluster'
export AIRFLOW_HOST_LOG_DIRECTORY='./logs'
export AIRFLOW_CONTAINER_LOG_DIRECTORY='/opt/airflow/logs'
export AIRFLOW_HOST_DAGS_DIRECTORY='./src/dags'
export AIRFLOW_CONTAINER_DAGS_DIRECTORY='/opt/airflow/dags'
export AIRFLOW_HOST_DATA_DIRECTORY='./data'
export AIRFLOW_CONTAINER_DATA_DIRECTORY='/data'
export AIRFLOW_BUILD_CONTEXT='docker/airflow'
export AIRFLOW_WORKER_DOCKERFILE='airflow-worker.Dockerfile'
export AIRFLOW_WORKER_COMMAND='celery worker'
export AIRFLOW_WORKER_HEALTHCHECK_TEST='celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
export AIRFLOW_WORKER_HEALTHCHECK_INTERVAL='5s'
export AIRFLOW_WORKER_HEALTHCHECK_TIMEOUT='5s'
export AIRFLOW_WORKER_HEALTHCHECK_RETRIES='5'
export AIRFLOW_INIT_USER='root'
export AIRFLOW_INIT_ENTRYPOINT='bash -c'
export AIRFLOW_WEBSERVER_COMMAND='webserver'
export AIRFLOW_WEBSERVER_HEALTHCHECK_TEST='curl --fail http://10.5.2.1:8080/health'
export AIRFLOW_WEBSERVER_HEALTHCHECK_INTERVAL='5s'
export AIRFLOW_WEBSERVER_HEALTHCHECK_TIMEOUT='5s'
export AIRFLOW_WEBSERVER_HEALTHCHECK_RETRIES='5'
export AIRFLOW_SCHEDULER_COMMAND='scheduler'
export AIRFLOW_SCHEDULER_HEALTHCHECK_TEST='airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"'
export AIRFLOW_SCHEDULER_HEALTHCHECK_INTERVAL='5s'
export AIRFLOW_SCHEDULER_HEALTHCHECK_TIMEOUT='5s'
export AIRFLOW_SCHEDULER_HEALTHCHECK_RETRIES='5'

# Localstack
export LOCALSTACK_DOCKER_HOST='unix:///var/run/docker.sock'
export LOCALSTACK_SERVICES='s3,lambda,sns,sqs,dynamodb'
export LOCALSTACK_EAGER_SERVICE_LOADING='1'
export LOCALSTACK_LAMBDA_DOCKER_NETWORK='localstack_default'
export LOCALSTACK_HOST_DOCKER_SOCKET='/var/run/docker.sock'
export LOCALSTACK_CONTAINER_DOCKER_SOCKET='/var/run/docker.sock'

# Postgres
export POSTGRES_AIRFLOW_USER='airflow'
export POSTGRES_AIRFLOW_PASSWORD='airflow'
export POSTGRES_AIRFLOW_DB='airflow'
export POSTGRES_HEALTHCHECK_TEST='pg_isready -U airflow'
export POSTGRES_HEALTHCHECK_INTERVAL='5s'
export POSTGRES_HEALTHCHECK_TIMEOUT='5s'
export POSTGRES_HEALTHCHECK_RETRIES='5'

# Redis
export REDIS_HEALTHCHECK_TEST='redis-cli ping'
export REDIS_HEALTHCHECK_INTERVAL='5s'
export REDIS_HEALTHCHECK_TIMEOUT='5s'
export REDIS_HEALTHCHECK_RETRIES='5'
